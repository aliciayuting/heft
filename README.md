# HEFT: Heterogeneous Earliest Finish Time

A Python 3.6+ implementation of a heuristic DAG scheduling approach from 

`H. Topcuoglu, S. Hariri and Min-You Wu, "Performance-effective and low-complexity task scheduling for heterogeneous computing," in IEEE Transactions on Parallel and Distributed Systems, vol. 13, no. 3, pp. 260-274, March 2002.`

[IEEE Explore Link](https://ieeexplore.ieee.org/document/993206)


## Installation
If you have conda installed, you can create an environment and fetch any necessary dependencies with

`conda env create -f heft.yml`

Otherwise, the main dependencies are:
- Python 3.6+ (uses literal string interpolation)
- Matplotlib
- Numpy
- Networkx
- Pytest (development dependency only)

## Usage
Basic usage is given by `python -m heft.heft -h`

```
usage: heft.py [-h] [-d DAG_FILE] [-p PE_CONNECTIVITY_FILE]                             
               [-t TASK_EXECUTION_FILE]                                                 
               [-l {DEBUG,INFO,WARNING,ERROR,CRITICAL}] [--showDAG]                     
               [--showGantt]                                                            
                                                                                        
A tool for finding HEFT schedules for given DAG task graphs                             
                                                                                        
optional arguments:                                                                     
  -h, --help            show this help message and exit                                 
  -d DAG_FILE, --dag_file DAG_FILE                                                      
                        File containing input DAG to be scheduled. Uses                 
                        default 10 node dag from Topcuoglu 2002 if none given.          
  -p PE_CONNECTIVITY_FILE, --pe_connectivity_file PE_CONNECTIVITY_FILE                  
                        File containing connectivity/bandwidth information              
                        about PEs. Uses a default 3x3 matrix from Topcuoglu             
                        2002 if none given.                                             
  -t TASK_EXECUTION_FILE, --task_execution_file TASK_EXECUTION_FILE                     
                        File containing execution times of each task on each            
                        particular PE. Uses a default 10x3 matrix from                  
                        Topcuoglu 2002 if none given.                                   
  -l {DEBUG,INFO,WARNING,ERROR,CRITICAL}, --loglevel {DEBUG,INFO,WARNING,ERROR,CRITICAL}
                        The log level to be used in this module. Default: INFO          
  --showDAG             Switch used to enable display of the incoming task DAG          
  --showGantt           Switch used to enable display of the final scheduled            
                        Gantt chart                                                     
```

If you don't have any particular DAG that needs scheduling, the canonical example schedule from Topcuoglu et al. can be generated by passing in no args

`python -m heft.heft`

With a generated Gantt chart available using

`python -m heft.heft --showGantt`

## Usage from an external library


```
from heft import heft

pe_connectivity_file = 'test/canonicalgraph_resource_BW.csv'
task_execution_file = 'test/canonicalgraph_task_exe_time.csv'
dag_file = 'test/canonicalgraph_task_connectivity.csv'

# Initialize the relevant HEFT matrices and DAG
communication_matrix = heft.readCsvToNumpyMatrix(pe_connectivity_file)
computation_matrix = heft.readCsvToNumpyMatrix(task_execution_file)
dag = heft.readDagMatrix(dag_file)

existing_schedules = None
time_offset = 0

"""
All keyword arguments have default values

proc_schedules gives a dictionary with keys being processor number and values being lists of tasks on each processor

task_schedules gives a dictionary with keys being node number (the label in the dag) and the values being the task of a particular job, potentially relabeled

matrix_schedules gives an Nx2 matrix representation (assuming N tasks) where each row represents a task. The first column of each row is the processor that task is scheduled on, and the second column of each row is the relative execution order of that task on that processor (i.e. (P1, 1st), (P1, 2nd), (P2, 1st), ...)
"""
proc_schedules, task_schedules, matrix_schedules = 
  heft.schedule_dag(
    dag, 
    communication_matrix=communication_matrix, 
    computation_matrix=computation_matrix, 
    proc_schedules=existing_schedules, 
    time_offset=time_offset,
    #If proc_schedules has schedules for nodes 1-10, then relabel your dag to be 11+
    relabel_nodes=True
  )
```

## Testing
If Pytest is installed, tests can be executed simply by running `pytest` from the repository root directory
